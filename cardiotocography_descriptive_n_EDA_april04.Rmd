---

---

<center>  <h3> Fayruz Kibria CIND 820 April 4 2022 </h2> </center>

---

## Imporing the rawdata sheet (sheet 3) from the library.


```{r}

# Imporing the rawdata sheet (sheet 3) from the library

library(readxl)
library(httr)
#packageVersion("readxl")

url<-'https://archive.ics.uci.edu/ml/machine-learning-databases/00193/CTG.xls'
GET(url, write_disk(tf <- tempfile(fileext = ".xls")))


```
## read rawdata as a dataframe

```{r}
# read raw data file in as dataframe

rawdata <- read_excel(tf, 3L)
#str(rawdata)
#head(rawdata)
#tail(rawdata)
```




## dropping incomplete cases, and irrelevant columns after examining head and tail of data

```{r}
# dropping incomplete cases, and irrelevant columns after examining head and tail of data

library(tidyr)

df1<-rawdata[!complete.cases(rawdata),]
df1<-rawdata %>% drop_na()
df1<- subset (df1, select = -c(FileName,Date,SegFile))
df1<-as.data.frame(df1)
head(df1)

```
## assigning col names, checking for missing data, and data description

```{r message=FALSE, warning=FALSE}
# assigning col names, checking for missing data, and data description

library(psych)


names <- c('Tendency', 'A',	'B',	'C',	'D',	'E',	'AD',	'DE',	'LD',	'FS',	'SUSP', 'CLASS', 'NSP')
df1[,names] <- lapply(df1[,names] , factor)

names <- c('AC',	'FM',	'UC',		'DL',	'DS',	'DP',	'DR', 'Nmax', 'Nzeros')
df1[,names] <- lapply(df1[,names] , as.integer)


cat("There are", sum(is.na(df1)), "missing data in the dataset.\n\n")

```

```{r}

describe(df1)

```
# deescription of categorical variables

```{r}
# deescription of categorical variables

library(SmartEDA)
ExpCTable(df1,Target=NULL,clim=5,nlim=15,round=2,bin=NULL,per=F)
ExpCustomStat(df1,Cvar=c("Tendency","A","B","C","D","E","AD","DE","LD","FS","SUSP","CLASS", "NSP"),gpby=FALSE)
```

## plotting all raw variable histogram

```{r message=FALSE, warning=FALSE}
# plotting all raw variable histogram

library(ggplot2)
library(gridExtra)

theme_set(
  theme_bw() +
    theme(legend.title=element_blank())+
    theme(legend.position = "top")
  )

temp<-df1

# b e
p=list()
namess<-c('b','e')
for (i in 1:length(namess)){
  p[[i]] <- ggplot(temp, aes_string(x = namess[i])) + 
  geom_histogram(aes(fill=factor(NSP, levels=c("3", "2", "1"))))
}
grid.arrange(grobs=p,ncol=2, nrow=2, top = "Variable histogram with NSP Classes")

#LBE	LB	
p=list()
namess<-c('LBE','LB')
for (i in 1:length(namess)){
  p[[i]] <- ggplot(temp, aes_string(x = namess[i])) + 
  geom_histogram(aes(fill=factor(NSP, levels=c("3", "2", "1"))))
}
grid.arrange(grobs=p,ncol=2, nrow=2, top = "Variable histogram with NSP Classes")

#AC	FM	UC	
p=list()
namess<-c('AC',	'FM',	'UC')
for (i in 1:length(namess)){
  p[[i]] <- ggplot(temp, aes_string(x = namess[i])) + 
  geom_bar(aes(fill=factor(NSP, levels=c("3", "2", "1"))))
}
grid.arrange(grobs=p,ncol=3, nrow=2, top = "Variable histogram with NSP Classes")

#	DL	DS	DP	DR
p=list()
namess<-c(	'DL',	'DS',	'DP',	'DR')
for (i in 1:length(namess)){
  p[[i]] <- ggplot(temp, aes_string(x = namess[i])) + 
  geom_bar(aes(fill=factor(NSP, levels=c("3", "2", "1"))))
}
grid.arrange(grobs=p,ncol=2, nrow=2, top = "Variable histogram with NSP Classes")

#ASTV	MSTV	ALTV	MLTV	
p=list()
namess<-c('ASTV',	'MSTV',	'ALTV',	'MLTV')
for (i in 1:length(namess)){
  p[[i]] <- ggplot(temp, aes_string(x = namess[i])) + 
  geom_histogram(aes(fill=factor(NSP, levels=c("3", "2", "1"))))
}
grid.arrange(grobs=p,ncol=2, nrow=2, top = "Variable histogram with NSP Classes")

# Mode	Mean	Median	Variance Tendency
p=list()
namess<-c('Mode',	'Mean',	'Median',	'Variance','Tendency')
for (i in 1:length(namess)){
  if(i < length(namess)){
  p[[i]] <- ggplot(temp, aes_string(x = namess[i])) + 
  geom_histogram(aes(fill=factor(NSP, levels=c("3", "2", "1"))))
  }else{
  p[[i]] <- ggplot(temp, aes_string(x = namess[i])) + 
  geom_bar(aes(fill=factor(NSP, levels=c("3", "2", "1"))))
  }
}
grid.arrange(grobs=p,ncol=3, nrow=2, top = "Variable histogram with NSP Classes")

# Width	Min	Max		Nmax	Nzeros 
p=list()
namess<-c('Width',	'Min',	'Max','Nmax',	'Nzeros' )
for (i in 1:length(namess)){
  p[[i]] <- ggplot(temp, aes_string(x = namess[i])) + 
  geom_histogram(aes(fill=factor(NSP, levels=c("3", "2", "1"))))
}
grid.arrange(grobs=p,ncol=3, nrow=2, top = "Variable histogram with NSP Classes")

#A	B	C	D	
p=list()
namess<-c('A',	'B',	'C',	'D')
for (i in 1:length(namess)){
  p[[i]] <- ggplot(temp, aes_string(x = namess[i])) + 
  geom_bar(aes(fill=factor(NSP, levels=c("3", "2", "1"))))
}
grid.arrange(grobs=p,ncol=2, nrow=2, top = "Variable histogram with NSP Classes")

#	E	AD	DE	LD
p=list()
namess<-c('E',	'AD',	'DE',	'LD')
for (i in 1:length(namess)){
  p[[i]] <- ggplot(temp, aes_string(x = namess[i])) + 
  geom_bar(aes(fill=factor(NSP, levels=c("3", "2", "1"))))
}
grid.arrange(grobs=p,ncol=2, nrow=2, top = "Variable histogram with NSP Classes")

#	FS	SUSP
p=list()
namess<-c('FS',	'SUSP')
for (i in 1:length(namess)){
  p[[i]] <- ggplot(temp, aes_string(x = namess[i])) + 
  geom_bar(aes(fill=factor(NSP, levels=c("3", "2", "1"))))
}
grid.arrange(grobs=p,ncol=2, nrow=2, top = "Variable histogram with NSP Classes")



# CLASS	NSP
p=list()
namess<-c( 'CLASS' ,	'NSP')
for (i in 1:length(namess)){
  p[[i]] <- ggplot(temp, aes_string(x = namess[i])) + 
  geom_bar(aes(fill=factor(NSP, levels=c("3", "2", "1"))))
}
grid.arrange(grobs=p,ncol=2, nrow=2, top = "Variable histogram with NSP Classes")

```


## checking if LBE and LB are exact duplicate columns in the dataset

```{r}

# checking if there are exact duplicate columns in the dataset

dup <- ifelse(df1$LBE > df1$LB, 1,ifelse(df1$LBE < df1$LB, 1, 0))
paste0("There are ",sum(dup)," items that are different in the LB anf LBE columns.")


```

## dropping the variable LBE because it is exact copy of the LB variable

```{r}
# dropping the variable LBE because it is exact copy of the LB variable

df2<- subset (df1, select = -c(DR, LBE))
#str(df2)

```

## calculating nPoints the length of record length variable from end and start instance numbers
## normalizing the recording length sensitive variables, adding them to the data set and dropping original cols

```{r}
# calculating nPoints the length of record length variable from end and start instance numbers
# normalizing the recording length sensitive variables, adding them to the data set and dropping original cols

library(dplyr)

df3 <- df2 %>% mutate(nPoints = e - b)

df3 <- df3 %>% mutate(nAC = AC/nPoints)
df3 <- df3 %>% mutate(nFM = FM/nPoints)
df3 <- df3 %>% mutate(nUC = UC/nPoints)
df3 <- df3 %>% mutate(nDL = DL/nPoints)
df3 <- df3 %>% mutate(nDS = DS/nPoints)
df3 <- df3 %>% mutate(nDP = DP/nPoints)


#df4 <- subset (df3, select = -c(b,	e,	AC,	FM,	UC,	DL,	DS,	DP))#, A, B, C, D, E, AD, DE, LD, FS, SUSP))

#str(df4)

```

## plotting recording length n points 

```{r message=FALSE, warning=FALSE}
# plotting n points and recording-length-normalized data

theme_set(
  theme_bw() +
    theme(legend.title=element_blank())+
    theme(legend.position = "top")
  )

temp<-df3

# nPoints
p=list()
namess<-c('nPoints')
for (i in 1:length(namess)){
  p[[i]] <- ggplot(temp, aes_string(x = namess[i])) + 
  geom_histogram(aes(fill=factor(NSP, levels=c("3", "2", "1"))))
}
grid.arrange(grobs=p,ncol=2, nrow=2, top = "Variable histogram with NSP Classes")


```

## saving normalized and not normalized dataframe for analysis in python

```{r}
# saving normalized and not normalized dataframe for analysis in python

library(tidyverse)


min_max_norm <- function(x) {
    (x - min(x)) / (max(x) - min(x))
  }

norm_df_0<- subset (df3, select = -c(b,	e,	AC,	FM,	UC,	DL,	DS,	DP))
norm_df_1 <- as.data.frame(sapply(norm_df_0 %>% select(where(is.numeric)), min_max_norm))
norm_df <- as.data.frame(cbind(norm_df_1, norm_df_0 %>% select(where(is.factor))))

# describeBy(norm_df, group=norm_df$NSP)
#str(norm_df)

write.csv(norm_df,"norm_df.csv", row.names = FALSE)

no_norm_df_0<- subset (df3, select = -c(b,	e,	nAC,	nFM,	nUC,	nDL,	nDS,	nDP))
no_norm_df<-as.data.frame(cbind(no_norm_df_0 %>% select(where(is.numeric)) ,no_norm_df_0 %>% select(where(is.factor)) ))

#str(no_norm_df)
write.csv(no_norm_df,"no_norm_df.csv", row.names = FALSE)


```


##plotting percentage distribution of NSP class by functionally grouped machine read variables

```{r}
library(Hmisc)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(scales)
library(rlang)


theme_set(
  theme_bw() +
    theme(legend.title=element_blank())+
    theme(legend.position = "top")
  )

temp<-no_norm_df

# 'LB','Mode', 'Mean', 'Median', 'Tendency'
p=list()
namess<-c('LB','Mode', 'Mean', 'Median', 'Tendency', 'nPoints')

i=1
for (var in namess){

new_temp = temp %>%
  select(sym(var), NSP)%>%
      group_by(.data[[var]], NSP) %>% 
        mutate(test = n()) %>%
          distinct(.data[[var]], NSP, test) %>%
            group_by(.data[[var]]) %>%
                mutate(pct = test/sum(test)*100)

p[[i]] <- ggplot(new_temp, aes(x= .data[[var]], y = pct)) +
              geom_bar(aes(fill=factor(NSP, levels=c("3", "2", "1"))), stat = "identity")+
              labs(x = var, y = "Percentage", 
                fill = "NSP Class")

i=i+1

}

grid.arrange(grobs=p,ncol=3, nrow=2, top = "Baseline tendencies with NSP Classes")



# 'AC',	'FM',	'Max', 'Nmax'
p=list()
namess<-c('AC',	'FM',	'Max', 'Nmax')
i=1
for (var in namess){

new_temp = temp %>%
  select(sym(var), NSP)%>%
      group_by(.data[[var]], NSP) %>% 
        mutate(test = n()) %>%
          distinct(.data[[var]], NSP, test) %>%
            group_by(.data[[var]]) %>%
                mutate(pct = test/sum(test)*100)


p[[i]] <- ggplot(new_temp, aes(x= .data[[var]], y = pct)) +
              geom_bar(aes(fill=factor(NSP, levels=c("3", "2", "1"))), stat = "identity")+
              labs(x = var, y = "Percentage", 
                fill = "NSP Class")

i=i+1

}
grid.arrange(grobs=p,ncol=3, nrow=2, top = "Accelerative tendencies with NSP Classes")

#	'DL',	'DS',	'DP',	'Min', 'Nzeros'
p=list()
namess<-c('DL',	'DS',	'DP',	'Min', 'Nzeros')
i=1
for (var in namess){

new_temp = temp %>%
  select(sym(var), NSP)%>%
      group_by(.data[[var]], NSP) %>% 
        mutate(test = n()) %>%
          distinct(.data[[var]], NSP, test) %>%
            group_by(.data[[var]]) %>%
                mutate(pct = test/sum(test)*100)

p[[i]] <- ggplot(new_temp, aes(x= .data[[var]], y = pct)) +
              geom_bar(aes(fill=factor(NSP, levels=c("3", "2", "1"))), stat = "identity")+
              labs(x = var, y = "Percentage", 
                fill = "NSP Class")

i=i+1

}
grid.arrange(grobs=p,ncol=3, nrow=2, top = "Decelerative tendencies with NSP Classes")

#'ASTV',	'MSTV',	'ALTV',	'MLTV',	'Variance','Width'
p=list()
namess<-c('ASTV',	'MSTV',	'ALTV',	'MLTV',	'Variance','Width')
i=1
for (var in namess){

new_temp = temp %>%
  select(sym(var), NSP)%>%
      group_by(.data[[var]], NSP) %>% 
        mutate(test = n()) %>%
          distinct(.data[[var]], NSP, test) %>%
            group_by(.data[[var]]) %>%
                mutate(pct = test/sum(test)*100)

p[[i]] <- ggplot(new_temp, aes(x= .data[[var]], y = pct)) +
              geom_bar(aes(fill=factor(NSP, levels=c("3", "2", "1"))), stat = "identity")+
              labs(x = var, y = "Percentage", 
                fill = "NSP Class")

i=i+1

}
grid.arrange(grobs=p,ncol=3, nrow=2, top = "Variability tendencies with NSP Classes")

#'UC'
p=list()
namess<-c('UC')
i=1
for (var in namess){

new_temp = temp %>%
  select(sym(var), NSP)%>%
      group_by(.data[[var]], NSP) %>% 
        mutate(test = n()) %>%
          distinct(.data[[var]], NSP, test) %>%
            group_by(.data[[var]]) %>%
                mutate(pct = test/sum(test)*100)



p[[i]] <- ggplot(new_temp, aes(x= .data[[var]], y = pct)) +
              geom_bar(aes(fill=factor(NSP, levels=c("3", "2", "1"))), stat = "identity")+
              labs(x = var, y = "Percentage", 
                fill = "NSP Class")

i=i+1

}
grid.arrange(grobs=p,ncol=3, nrow=2, top = "Uterine contraction tendencies with NSP Classes")


```


## plotting pairwise colleration for machine variables grouped by function

```{r}
library(psych)

dataframe0<-no_norm_df

pairs.panels(dataframe0[,c('LB','Mean', 'Median', 'Mode', 'Tendency', 'nPoints','NSP')], 
             bg=c("red","yellow","blue")[dataframe0$NSP],
             method = "spearman", # correlation method
             hist.col = "#00AFBB",
             density = TRUE,  # show density plots
             ellipses = TRUE # show correlation ellipses
             )
pairs.panels(dataframe0[,c('AC','FM','Nmax','Max','NSP')], 
             method = "spearman", # correlation method
             hist.col = "#00AFBB",
             density = TRUE,  # show density plots
             ellipses = TRUE # show correlation ellipses  
             )
pairs.panels(dataframe0[,c('DL','DS','DP','Min','Nzeros','NSP')], 
             method = "spearman", # correlation method
             hist.col = "#00AFBB",
             density = TRUE,  # show density plots
             ellipses = TRUE # show correlation ellipses  5,6,7,13,
             )

pairs.panels(dataframe0[,c('ASTV','ALTV','MSTV','MLTV','Width','Variance','NSP')], 
             method = "spearman", # correlation method
             hist.col = "#00AFBB",
             density = TRUE,  # show density plots
             ellipses = TRUE # show correlation ellipses  5,6,7,13,
             )
pairs.panels(dataframe0[,c('LB','FM','UC','DL','NSP')], 
             method = "spearman", # correlation method
             hist.col = "#00AFBB",
             density = TRUE,  # show density plots
             ellipses = TRUE # show correlation ellipses  5,6,7,13,
             )
```


#### Exploring the correlation between the attributes other than class attribute

```{r}
# correlation plot of all the min max normalized numerical variables

library(corrplot)


col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(round(cor(select_if(no_norm_df, is.numeric)),1), method="color", col=col(200),  
         type="lower", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=90, number.cex= .6,#Text label color and rotation
         # hide correlation coefficient on the principal diagonal
         diag=FALSE 
         )
```
## spearmans correlation for machine data

```{r}

library(ggcorrplot)


machine_names<-c('nPoints','LB','AC',	'FM',	'UC',	'DL',	'DS',	'DP',	'ASTV',	'MSTV',	'ALTV',	'MLTV',	'Width', 'Min',	'Max',	'Nmax',	'Nzeros',	'Mode',	'Mean',	'Median',	'Variance',	'Tendency','NSP')

machine_data<-subset (no_norm_df, select = machine_names)
names <- c('Tendency','NSP')
machine_data[,names] <- as.data.frame(lapply(machine_data[,names] , as.integer))

morpho_names<-c('A'	,'B',	'C',	'D',	'E',	'AD',	'DE',	'LD',	'FS',	'SUSP',		'CLASS','NSP')

morpho_data<-no_norm_df[,morpho_names]

names <- c('A'	,'B',	'C',	'D',	'E',	'AD',	'DE',	'LD',	'FS',	'SUSP',		'CLASS','NSP')
morpho_data[,names] <- lapply(morpho_data[,names] , as.integer)

#pairwise.complete.obs spearman
model.matrix(~0+., data=machine_data) %>% 
  cor(use="pairwise.complete.obs", method = 'spearman') %>% 
  ggcorrplot(show.diag = F, type="upper", lab=TRUE, lab_size=2, tl.srt = 90, colors = c( "#1F51FF", "white","#DC143C"))+
  scale_x_discrete(position='top')+
  theme(aspect.ratio=3/4, axis.text.x.top = element_text(angle = 90,hjust = 0,vjust = 0.5))
  

#model.matrix to one-hot encode all non-numeric variables. This is quite different than calculating Cramér's V as it will consider your factor as separate variables

```
## spearmans correlation for morphological data

```{r}


model.matrix(~0+., data=morpho_data) %>% 
  cor(use="pairwise.complete.obs", method = 'spearman') %>% 
  ggcorrplot(show.diag = F, type="upper", lab=TRUE, lab_size=2, tl.srt = 90, colors = c( "#1F51FF", "white","#DC143C"))+
  scale_x_discrete(position='top')+
  theme( axis.text.x.top = element_text(angle = 90,hjust = 0,vjust = 0.5))
```

## kruskal test on the machine dataset, see most affected variables by NSP class

```{r warning=FALSE}
library(broom)
no_norm_df_machine <- subset (no_norm_df, select = -c(A, B, C, D, E, AD, DE, LD, FS, SUSP, CLASS))

kwt_df <- no_norm_df_machine %>% gather(key, value, -NSP) %>% 
       group_by(key) %>% 
       do(tidy(kruskal.test(x= .$value, g = .$NSP)))

kwt_df[with(kwt_df, order(p.value, statistic)), ]

#str(no_norm_df_machine)
```

## kruskal test on the machine dataset, see least affected variables by NSP class
```{r}
kwt_df[with(kwt_df, order(-p.value, statistic)), ]
```



##class imbalance analysis for the whole dataset

```{r}
#class imbalance analysis for the whole dataset

C<-3

Tdata<-length(no_norm_df$NSP)

n1<-length(which(no_norm_df$NSP=="1"))
n2<-length(which(no_norm_df$NSP=="2"))
n3<-length(which(no_norm_df$NSP=="3"))

imbalanceStat<-abs(((1/C)-(n1/Tdata)))+abs(((1/C)-(n2/Tdata)))+abs(((1/C)-(n3/Tdata)))

cat("Class 1: ",round(n1*100/Tdata,0),"%\n")
cat("Class 2: ",round(n2*100/Tdata,0),"%\n")
cat("Class 3: ",round(n3*100/Tdata,0),"%\n\n")
cat("Imbalance: ",round(imbalanceStat,2))
```


#--------------------------------------------------------------------------

## plotting the out put of the train test split in python thi section must run after the python script has produced the outputs

```{r}

# importing the python train test split for plotting

train_pthn <- read.csv(file = 'X_y_train_combined.csv', )
test_pthn <- read.csv(file = 'X_y_test_combined.csv', )

names <- c('Tendency', 'A',	'B',	'C',	'D',	'E',	'AD',	'DE',	'LD',	'FS',	'SUSP', 'CLASS', 'NSP')
train_pthn[,names] <- lapply(train_pthn[,names] , factor)
test_pthn[,names] <- lapply(test_pthn[,names] , factor)

#head(test_pthn)
```

```{r}
library(ggplot2)
library(gridExtra)
 theme_set(
   theme_bw() +
     theme(legend.title=element_blank())+
     theme(legend.position = "top")
   )

p<-list()
p[[1]] <- ggplot(train_pthn, aes(x=NSP)) + 
    geom_bar(aes(fill=factor(NSP, levels=c("3", "2", "1"))))+
  geom_text(stat='count', aes(label=..count..), vjust=1.25)+
  ggtitle("Train Set NSP Count")+
  theme(plot.title = element_text(hjust = 0.5))
p[[2]] <- ggplot(test_pthn, aes(x=NSP)) + 
  geom_bar(aes(fill=factor(NSP, levels=c("3", "2", "1"))))+
  geom_text(stat='count', aes(label=..count..), vjust=1.25)+
  ggtitle("Test Set NSP Count")+
  theme(plot.title = element_text(hjust = 0.5))
grid.arrange(grobs=p,ncol=2, nrow=1)


```



##Importing the results of the classification models from python, decision tree, randome forest, and SVC

```{r}

# importing the python train test split for plotting

final_result <- read.csv(file = 'all_3_model_results.csv')


names <- c('sampling', 'model.name',	'normalization')
final_result[,names] <- lapply(final_result[,names] , factor)


head(final_result)

```
## organizing result data to plot for accuracy of the results

```{r}
library(reshape2)

val_acc<- final_result[, c('test.imbalance', 'validation.accuracy','normalization', 'sampling', 'model.name')]

val_acc$procedure<-as.factor('validation')
names(val_acc)[names(val_acc) == 'validation.accuracy'] <- 'proc_accuracy'

test_acc<- final_result[, c('test.imbalance', 'test.accuracy','normalization', 'sampling', 'model.name')]

test_acc$procedure<-as.factor('test')
names(test_acc)[names(test_acc) == 'test.accuracy'] <- 'proc_accuracy'


acc<-rbind(val_acc, test_acc)
meltdf_acc<-melt(acc, id.var = c('test.imbalance','normalization', 'sampling', 'model.name', 'procedure'), variable.name = 'accuracy')

meltdf_acc_norm<-meltdf_acc[meltdf_acc$normalization=='norm',]
meltdf_acc_nonorm<-meltdf_acc[meltdf_acc$normalization=='no_norm',]

head(meltdf_acc_norm)

```

## plotting accuracy of validation and test data as a function of other variables

```{r message=FALSE, warning=FALSE}

library(reshape2)

ggplot(data=meltdf_acc_norm, aes(x=test.imbalance, y=value, col = normalization, group=procedure,linetype=procedure)) + 

    geom_point(size=1) +
    geom_smooth(method=lm, se=FALSE, size=0.5)+
  
    geom_point(data=meltdf_acc_nonorm,, size=1) +
    geom_smooth(data=meltdf_acc_nonorm,method=lm, se=FALSE, size=0.5)+
    facet_grid(model.name ~ sampling, margins=TRUE)+
  
    xlab('Test Imbalance')+
    ylab("Accuracy")

```
## reorganizing data to plot the f1 score of class 3 for each classification model and balancing techniques and values

```{r}

val_f1<- final_result[, c('test.imbalance', 'validation.f1','normalization', 'sampling', 'model.name')]

val_f1$procedure<-as.factor('validation')
names(val_f1)[names(val_f1) == 'validation.f1'] <- 'proc_f1'

test_f1<- final_result[, c('test.imbalance', 'test.f1','normalization', 'sampling', 'model.name')]

test_f1$procedure<-as.factor('test')
names(test_f1)[names(test_f1) == 'test.f1'] <- 'proc_f1'


f1<-rbind(val_f1, test_f1)

meltdf_f1<-melt(f1, id.var = c('test.imbalance','normalization', 'sampling', 'model.name', 'procedure'), variable.name = 'f1')

meltdf_f1_norm<-meltdf_f1[meltdf_f1$normalization=='norm',]
meltdf_f1_nonorm<-meltdf_f1[meltdf_f1$normalization=='no_norm',]

head(meltdf_f1_norm)

```
## plot of f1 score for class 3 for each of the models and upsampling methods and imbalances

```{r}
ggplot(data=meltdf_f1_norm, aes(x=test.imbalance, y=value, col = normalization, group=procedure,linetype=procedure)) + 

    geom_point(size=1) +
    geom_smooth(method=lm, se=FALSE, size=0.5)+
  
    geom_point(data=meltdf_f1_nonorm,, size=1) +
    geom_smooth(data=meltdf_f1_nonorm,method=lm, se=FALSE, size=0.5)+
    facet_grid(model.name ~ sampling, margins=TRUE)+
  
    xlab('Test Imbalance')+
    ylab("Class 3 f1 score")
```
## arrangind data to show the time taken in each step

```{r}
val_time<- final_result[, c('test.imbalance', 'validation.f1','normalization', 'sampling', 'model.name', 'time')]

val_time$procedure<-as.factor('validation')
names(val_time)[names(val_time) == 'validation.f1'] <- 'proc'

test_time<- final_result[, c('test.imbalance', 'test.f1','normalization', 'sampling', 'model.name', 'time')]

test_time$procedure<-as.factor('test')
names(test_time)[names(test_time) == 'test.f1'] <- 'proc'


time_df<-rbind(val_time, test_time)
time_df <- subset(time_df, select = -c(proc) )

meltdf_time<-melt(time_df, id.var = c('test.imbalance','normalization', 'sampling', 'model.name', 'procedure'), variable.name = 'time')

meltdf_time_norm<-meltdf_time[meltdf_time$normalization=='norm',]
meltdf_time_nonorm<-meltdf_time[meltdf_time$normalization=='no_norm',]

head(meltdf_time_norm)
```
## plot of time taken as a function of other variables

```{r warning=FALSE}
ggplot(data=meltdf_time_norm, aes(x=test.imbalance, y=value/60, col = normalization, group=procedure,linetype=procedure)) + 

    geom_point(size=1) +
    geom_smooth(method=lm, se=FALSE, size=0.5)+
  
    geom_point(data=meltdf_time_nonorm,, size=1) +
    geom_smooth(data=meltdf_time_nonorm,method=lm, se=FALSE, size=0.5)+
    facet_grid(model.name ~ sampling, margins=TRUE)+
  
    xlab('Test Imbalance')+
    ylab("Classification Time Taken (mins)")
```
## future work investigating the relations of the FS parameter

```{r}



describeBy(no_norm_df, group="FS")


```

